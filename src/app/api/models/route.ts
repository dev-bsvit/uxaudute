import { NextRequest, NextResponse } from 'next/server'
import OpenAI from 'openai'

// GET /api/models - –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π OpenAI
export async function GET(request: NextRequest) {
  try {
    // –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ API –∫–ª—é—á–∞
    if (!process.env.OPENAI_API_KEY) {
      return NextResponse.json(
        { 
          success: false, 
          error: 'OpenAI API key not configured' 
        },
        { status: 500 }
      )
    }

    // –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç OpenAI
    const client = new OpenAI({ 
      apiKey: process.env.OPENAI_API_KEY 
    })

    console.log('üîç –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π OpenAI...')

    // –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
    const models = await client.models.list()

    console.log(`‚úÖ –ü–æ–ª—É—á–µ–Ω–æ ${models.data.length} –º–æ–¥–µ–ª–µ–π`)

    // –§–∏–ª—å—Ç—Ä—É–µ–º –∏ –≥—Ä—É–ø–ø–∏—Ä—É–µ–º –º–æ–¥–µ–ª–∏
    const modelList = models.data.map(model => ({
      id: model.id,
      object: model.object,
      created: model.created,
      owned_by: model.owned_by,
      // –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –º–æ–¥–µ–ª–∏ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é
      type: getModelType(model.id),
      // –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏
      capabilities: getModelCapabilities(model.id)
    }))

    // –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –º–æ–¥–µ–ª–∏ –ø–æ —Ç–∏–ø–∞–º
    const groupedModels = {
      gpt4: modelList.filter(m => m.type === 'gpt4'),
      gpt3_5: modelList.filter(m => m.type === 'gpt3.5'),
      dall_e: modelList.filter(m => m.type === 'dall-e'),
      tts: modelList.filter(m => m.type === 'tts'),
      whisper: modelList.filter(m => m.type === 'whisper'),
      other: modelList.filter(m => m.type === 'other')
    }

    // –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è UX –∞–Ω–∞–ª–∏–∑–∞
    const recommendedForUX = modelList.filter(model => 
      model.id.includes('gpt-4') && 
      (model.id.includes('o') || model.id.includes('turbo'))
    )

    return NextResponse.json({
      success: true,
      total: models.data.length,
      recommended_for_ux: recommendedForUX,
      models_by_type: groupedModels,
      all_models: modelList,
      current_model: process.env.OPENAI_MODEL || 'gpt-4o',
      timestamp: new Date().toISOString()
    })

  } catch (error) {
    console.error('‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π:', error)
    
    return NextResponse.json({
      success: false,
      error: 'Failed to fetch models',
      details: error instanceof Error ? error.message : 'Unknown error',
      timestamp: new Date().toISOString()
    }, { status: 500 })
  }
}

// –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ –º–æ–¥–µ–ª–∏
function getModelType(modelId: string): string {
  if (modelId.includes('gpt-4')) {
    return 'gpt4'
  } else if (modelId.includes('gpt-3.5')) {
    return 'gpt3.5'
  } else if (modelId.includes('dall-e')) {
    return 'dall-e'
  } else if (modelId.includes('tts')) {
    return 'tts'
  } else if (modelId.includes('whisper')) {
    return 'whisper'
  } else {
    return 'other'
  }
}

// –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –º–æ–¥–µ–ª–∏
function getModelCapabilities(modelId: string): string[] {
  const capabilities: string[] = []
  
  if (modelId.includes('gpt-4')) {
    capabilities.push('text-generation', 'json-mode', 'function-calling')
    if (modelId.includes('o')) {
      capabilities.push('vision', 'image-analysis')
    }
    if (modelId.includes('turbo')) {
      capabilities.push('fast-response')
    }
  } else if (modelId.includes('gpt-3.5')) {
    capabilities.push('text-generation', 'json-mode', 'function-calling')
  } else if (modelId.includes('dall-e')) {
    capabilities.push('image-generation')
  } else if (modelId.includes('tts')) {
    capabilities.push('text-to-speech')
  } else if (modelId.includes('whisper')) {
    capabilities.push('speech-to-text')
  }
  
  return capabilities
}
