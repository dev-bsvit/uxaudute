import { NextRequest, NextResponse } from 'next/server'
import { openai } from '@/lib/openai'
import { promptService } from '@/lib/i18n/prompt-service'
import { PromptType } from '@/lib/i18n/types'

export async function POST(request: NextRequest) {
  try {
    console.log('=== RESEARCH API called ===')
    const { url, screenshot, context, language } = await request.json()

    if (!url && !screenshot) {
      return NextResponse.json(
        { error: 'URL –∏–ª–∏ —Å–∫—Ä–∏–Ω—à–æ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞' },
        { status: 400 }
      )
    }

    // –û–ø—Ä–µ–¥–µ–ª—è–µ–º —è–∑—ã–∫ (–ø—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞)
    const detectedLanguage = language || 
      request.headers.get('accept-language')?.includes('ru') ? 'ru' : 'en'
    
    console.log(`üåê Using language: ${detectedLanguage}`)

    // –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ–º–ø—Ç
    console.log(`üîç Loading prompt for language: ${detectedLanguage}`)
    let mainPrompt = await promptService.loadPrompt(PromptType.JSON_STRUCTURED, detectedLanguage)
    
    // –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
    let finalPrompt = promptService.combineWithContext(mainPrompt, context, detectedLanguage)

    console.log('üîç Final prompt ready, length:', finalPrompt.length)

    let analysisResult: string | null = null

    if (url) {
      // –ê–Ω–∞–ª–∏–∑ URL
      console.log('üîç Analyzing URL:', url)
      const urlInstruction = detectedLanguage === 'ru'
        ? `\n\n–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–∞–π—Ç –ø–æ URL: ${url}\n\n–ü–æ—Å–∫–æ–ª—å–∫—É —è –Ω–µ –º–æ–≥—É –ø–æ–ª—É—á–∏—Ç—å —Å–∫—Ä–∏–Ω—à–æ—Ç, –ø—Ä–æ–≤–µ–¥–∏ –∞–Ω–∞–ª–∏–∑ –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –æ–±—â–∏—Ö –ø—Ä–∏–Ω—Ü–∏–ø–∞—Ö UX –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞ —Å–∞–π—Ç–∞.`
        : `\n\nAnalyze the website at URL: ${url}\n\nSince I cannot get a screenshot, conduct analysis based on general UX principles for this type of website.`
      
      const analysisPrompt = finalPrompt + urlInstruction
      
      const completion = await openai.chat.completions.create({
        model: "gpt-4o",
        messages: [{ role: "user", content: analysisPrompt }],
        temperature: 0.7,
        max_tokens: 4096,
        response_format: { type: "json_object" }
      })

      analysisResult = completion.choices[0]?.message?.content || null
    }

    if (screenshot) {
      // –ê–Ω–∞–ª–∏–∑ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞
      console.log('üîç Analyzing screenshot')
      
      const completion = await openai.chat.completions.create({
        model: "gpt-4o",
        messages: [
          {
            role: "user",
            content: [
              { type: "text", text: finalPrompt },
              {
                type: "image_url",
                image_url: {
                  url: screenshot,
                  detail: "high"
                }
              }
            ]
          }
        ],
        temperature: 0.7,
        max_tokens: 4096,
        response_format: { type: "json_object" }
      })

      analysisResult = completion.choices[0]?.message?.content || null
    }

    // –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø–æ–ª—É—á–∏–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    if (!analysisResult) {
      console.error('‚ùå No analysis result received')
      return NextResponse.json(
        { error: '–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞' },
        { status: 500 }
      )
    }

    console.log('‚úÖ Analysis completed successfully')

    return NextResponse.json({ 
      result: analysisResult
    })

  } catch (error) {
    console.error('Research API error:', error)
    
    // –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ—à–∏–±–∫–µ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
    if (error instanceof Error) {
      console.error('Error message:', error.message)
      console.error('Error stack:', error.stack)
    }
    
    return NextResponse.json(
      { error: '–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∞–Ω–∞–ª–∏–∑. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.' },
      { status: 500 }
    )
  }
}


